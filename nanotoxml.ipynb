{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development of a Machine Learning Model to Predict the Cytotoxicity of Nanoparticles in Cell Cultures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pymatgen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preliminary adjustments\n",
    "### 2.1. Info about dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name - Missing Values (%) - Data Type\n",
      "Unnamed: 0 - 0.00% - int64\n",
      "material - 0.00% - object\n",
      "shape - 49.19% - object\n",
      "coat/functional group - 69.00% - object\n",
      "synthesismethod - 49.19% - object\n",
      "surface charge - 47.60% - object\n",
      "size in medium (nm) - 73.96% - float64\n",
      "zeta in medium (mV) - 79.97% - float64\n",
      "no of cells (cells/well) - 53.89% - float64\n",
      "human/animal - 16.15% - object\n",
      "cell source - 7.48% - object\n",
      "cell tissue - 7.48% - object\n",
      "cell morphology - 16.15% - object\n",
      "cell age - 16.15% - object\n",
      "time (hr) - 7.48% - float64\n",
      "concentration (ug/ml) - 36.07% - float64\n",
      "test - 7.48% - object\n",
      "test indicator - 16.15% - object\n",
      "viability (%) - 0.00% - float64\n",
      "DOI - 16.15% - object\n",
      "core size (nm) - 83.85% - float64\n",
      "surface area - 83.85% - float64\n",
      "Hydrodynamic diameter (nm) - 2.23% - float64\n",
      "Zeta potential (mV) - 41.96% - float64\n",
      "Cell type - 7.48% - object\n",
      "Molecular weight (g/mol) - 16.15% - float64\n"
     ]
    }
   ],
   "source": [
    "# Path to the dataset\n",
    "data_path = \"C:\\\\Users\\\\tikli\\\\Desktop\\\\NanoToxML\\\\Tox_DB.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Function to display detailed information about the dataset\n",
    "def dataset_detailed_overview(dataframe):\n",
    "    # Calculate the percentage of missing values for each column\n",
    "    missing_percentage = dataframe.isnull().mean() * 100\n",
    "    \n",
    "    # Print header\n",
    "    print(\"Column Name - Missing Values (%) - Data Type\")\n",
    "    \n",
    "    # Loop through each column and print the desired information\n",
    "    for col in dataframe.columns:\n",
    "        print(f\"{col} - {missing_percentage[col]:.2f}% - {dataframe[col].dtype}\")\n",
    "\n",
    "# Call the function with your dataset\n",
    "dataset_detailed_overview(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Dropping Unnecessary colomns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved to C:\\Users\\tikli\\Desktop\\NanoToxML\\Tox_DB_Cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Drop the unnecessary columns\n",
    "data_cleaned = data.drop(['Unnamed: 0', 'DOI'], axis=1)\n",
    "\n",
    "# Define the path for the new CSV file\n",
    "new_data_path = 'C:\\\\Users\\\\tikli\\\\Desktop\\\\NanoToxML\\\\Tox_DB_Cleaned.csv'\n",
    "\n",
    "# Save the cleaned dataset to a new CSV file\n",
    "data_cleaned.to_csv(new_data_path, index=False)\n",
    "\n",
    "print(f\"Cleaned dataset saved to {new_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Cell Sources:\n",
      "Rat\n",
      "Mouse\n",
      "Monkey\n",
      "Dog\n",
      "Human\n",
      "Porcine\n",
      "Rabbit\n",
      "Catfish\n",
      "Hamster\n",
      "Pig\n",
      "Monkey (Cercopithecus aethiops)\n",
      "Canine\n",
      "hamster\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_path = 'C:\\\\Users\\\\tikli\\\\Desktop\\\\NanoToxML\\\\Tox_DB_Cleaned.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Get all unique variations in the 'cell source' column\n",
    "unique_cell_sources = data['cell source'].unique()\n",
    "\n",
    "# Print all unique cell sources\n",
    "print(\"Unique Cell Sources:\")\n",
    "for source in unique_cell_sources:\n",
    "    print(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where both 'human/animal' and 'cell source' are missing: 494\n",
      "Rows where only 'human/animal' is missing and 'cell source' is available: 572\n",
      "Rows where only 'cell source' is missing and 'human/animal' is available: 0\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_path = 'C:\\\\Users\\\\tikli\\\\Desktop\\\\NanoToxML\\\\Tox_DB_Cleaned.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Check for missing values in both columns\n",
    "missing_human_animal = data['human/animal'].isnull()\n",
    "missing_cell_source = data['cell source'].isnull()\n",
    "\n",
    "# Calculate the scenarios\n",
    "both_missing = data[missing_human_animal & missing_cell_source].shape[0]\n",
    "only_human_animal_missing = data[missing_human_animal & ~missing_cell_source].shape[0]\n",
    "only_cell_source_missing = data[~missing_human_animal & missing_cell_source].shape[0]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Rows where both 'human/animal' and 'cell source' are missing: {both_missing}\")\n",
    "print(f\"Rows where only 'human/animal' is missing and 'cell source' is available: {only_human_animal_missing}\")\n",
    "print(f\"Rows where only 'cell source' is missing and 'human/animal' is available: {only_cell_source_missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset saved to C:\\Users\\tikli\\Desktop\\NanoToxML\\Tox_DB_Updated.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_path = 'C:\\\\Users\\\\tikli\\\\Desktop\\\\NanoToxML\\\\Tox_DB_Cleaned.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Drop the 'human/animal' column\n",
    "data_dropped = data.drop('human/animal', axis=1)\n",
    "\n",
    "# Define the path for the new CSV file\n",
    "new_data_path = 'C:\\\\Users\\\\tikli\\\\Desktop\\\\NanoToxML\\\\Tox_DB_Updated.csv'\n",
    "\n",
    "# Save the updated dataset to a new CSV file\n",
    "data_dropped.to_csv(new_data_path, index=False)\n",
    "\n",
    "print(f\"Updated dataset saved to {new_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Dropping colomns with more than 20% missing values and less meaningful ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has been updated and overwritten at C:\\Users\\tikli\\Desktop\\NanoToxML\\Tox_DB_Updated.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_path = 'C:\\\\Users\\\\tikli\\\\Desktop\\\\NanoToxML\\\\Tox_DB_Updated.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Calculate the percentage of missing values for each column\n",
    "missing_percentages = data.isnull().mean() * 100\n",
    "\n",
    "# Identify and drop columns with more than 20% missing values\n",
    "columns_to_drop = missing_percentages[missing_percentages > 20].index\n",
    "data_cleaned = data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Overwrite the original dataset with the cleaned data\n",
    "data_cleaned.to_csv(data_path, index=False)\n",
    "\n",
    "print(\"The dataset has been updated and overwritten at\", data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns 'Cell Morphology' and 'Cell Age' have been removed and the dataset has been updated.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_path = 'C:\\\\Users\\\\tikli\\\\Desktop\\\\NanoToxML\\\\Tox_DB_Updated.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Drop the 'Cell Morphology' and 'Cell Age' columns\n",
    "data_cleaned = data.drop(columns=['cell morphology', 'cell age'])\n",
    "\n",
    "# Overwrite the original dataset with the updated data\n",
    "data_cleaned.to_csv(data_path, index=False)\n",
    "\n",
    "print(\"Columns 'Cell Morphology' and 'Cell Age' have been removed and the dataset has been updated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Info about data before encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name - Missing Values (%) - Data Type\n",
      "material - 0.00% - object\n",
      "cell source - 7.48% - object\n",
      "cell tissue - 7.48% - object\n",
      "time (hr) - 7.48% - float64\n",
      "test - 7.48% - object\n",
      "test indicator - 16.15% - object\n",
      "viability (%) - 0.00% - float64\n",
      "Hydrodynamic diameter (nm) - 2.23% - float64\n",
      "Cell type - 7.48% - object\n",
      "Molecular weight (g/mol) - 16.15% - float64\n"
     ]
    }
   ],
   "source": [
    "# Path to the dataset\n",
    "data_path = 'C:\\\\Users\\\\tikli\\\\Desktop\\\\NanoToxML\\\\Tox_DB_Updated.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Function to display detailed information about the dataset\n",
    "def dataset_detailed_overview(dataframe):\n",
    "    # Calculate the percentage of missing values for each column\n",
    "    missing_percentage = dataframe.isnull().mean() * 100\n",
    "    \n",
    "    # Print header\n",
    "    print(\"Column Name - Missing Values (%) - Data Type\")\n",
    "    \n",
    "    # Loop through each column and print the desired information\n",
    "    for col in dataframe.columns:\n",
    "        print(f\"{col} - {missing_percentage[col]:.2f}% - {dataframe[col].dtype}\")\n",
    "\n",
    "# Call the function with your dataset\n",
    "dataset_detailed_overview(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adding additional database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Merging the databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to C:\\Users\\tikli\\Desktop\\NanoToxML\\Merged_Tox_Data.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the file paths\n",
    "tox_data_path = 'C:\\\\Users\\\\tikli\\\\Desktop\\\\NanoToxML\\\\Tox_DB_Updated.csv'\n",
    "inorg_prop_data_path = 'C:\\\\Users\\\\tikli\\\\Desktop\\\\NanoToxML\\\\inorg prop - 1.csv'\n",
    "output_path = 'C:\\\\Users\\\\tikli\\\\Desktop\\\\NanoToxML\\\\Merged_Tox_Data.csv'\n",
    "\n",
    "# Load the datasets\n",
    "tox_data = pd.read_csv(tox_data_path)\n",
    "inorg_prop_data = pd.read_csv(inorg_prop_data_path)\n",
    "\n",
    "# Handle duplicates by averaging the values for each formula\n",
    "inorg_prop_data_aggregated = inorg_prop_data.groupby('formula').mean().reset_index()\n",
    "\n",
    "# Create a dictionary from the aggregated inorganic properties data for quick lookup\n",
    "inorg_prop_dict = inorg_prop_data_aggregated.set_index('formula').to_dict('index')\n",
    "\n",
    "# Add columns for inorganic properties to the tox_data dataframe\n",
    "tox_data['AR'] = tox_data['material'].map(lambda x: inorg_prop_dict.get(x, {}).get('AR'))\n",
    "tox_data['IR'] = tox_data['material'].map(lambda x: inorg_prop_dict.get(x, {}).get('IR'))\n",
    "tox_data['X'] = tox_data['material'].map(lambda x: inorg_prop_dict.get(x, {}).get('X'))\n",
    "tox_data['E'] = tox_data['material'].map(lambda x: inorg_prop_dict.get(x, {}).get('E'))\n",
    "tox_data['pot'] = tox_data['material'].map(lambda x: inorg_prop_dict.get(x, {}).get('pot'))\n",
    "\n",
    "# Save the merged data to a new CSV file\n",
    "tox_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Merged data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name - Missing Values (%) - Data Type\n",
      "material - 0.00% - object\n",
      "cell source - 7.48% - object\n",
      "cell tissue - 7.48% - object\n",
      "time (hr) - 7.48% - float64\n",
      "test - 7.48% - object\n",
      "test indicator - 16.15% - object\n",
      "viability (%) - 0.00% - float64\n",
      "Hydrodynamic diameter (nm) - 2.23% - float64\n",
      "Cell type - 7.48% - object\n",
      "Molecular weight (g/mol) - 16.15% - float64\n",
      "AR - 34.22% - float64\n",
      "IR - 34.22% - float64\n",
      "X - 34.22% - float64\n",
      "E - 34.22% - float64\n",
      "pot - 53.66% - float64\n"
     ]
    }
   ],
   "source": [
    "# Path to the dataset\n",
    "data_path = 'C:\\\\Users\\\\tikli\\\\Desktop\\\\NanoToxML\\\\Merged_Tox_Data.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Function to display detailed information about the dataset\n",
    "def dataset_detailed_overview(dataframe):\n",
    "    # Calculate the percentage of missing values for each column\n",
    "    missing_percentage = dataframe.isnull().mean() * 100\n",
    "    \n",
    "    # Print header\n",
    "    print(\"Column Name - Missing Values (%) - Data Type\")\n",
    "    \n",
    "    # Loop through each column and print the desired information\n",
    "    for col in dataframe.columns:\n",
    "        print(f\"{col} - {missing_percentage[col]:.2f}% - {dataframe[col].dtype}\")\n",
    "\n",
    "# Call the function with your dataset\n",
    "dataset_detailed_overview(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Adjustment to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset saved to C:\\Users\\tikli\\Desktop\\NanoToxML\\Updated_Merged_Tox_Data.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Define the path to the directory\n",
    "directory_path = \"C:\\\\Users\\\\tikli\\\\Desktop\\\\NanoToxML\"\n",
    "\n",
    "# Load the datasets\n",
    "tox_db_updated_path = f\"{directory_path}\\\\Tox_DB_Updated.csv\"\n",
    "inorg_prop_path = f\"{directory_path}\\\\inorg prop - 1.csv\"\n",
    "redox_redox_path = f\"{directory_path}\\\\redox - redox.csv\"\n",
    "merged_tox_data_path = f\"{directory_path}\\\\Merged_Tox_Data.csv\"\n",
    "\n",
    "tox_db_updated = pd.read_csv(tox_db_updated_path)\n",
    "inorg_prop = pd.read_csv(inorg_prop_path)\n",
    "redox_redox = pd.read_csv(redox_redox_path)\n",
    "merged_tox_data = pd.read_csv(merged_tox_data_path)\n",
    "\n",
    "# Function to decompose a chemical formula into its constituent elements\n",
    "def parse_formula(formula):\n",
    "    \"\"\"\n",
    "    Parse a chemical formula into its constituent elements.\n",
    "    \"\"\"\n",
    "    # Regex to match elements and their counts\n",
    "    pattern = r'([A-Z][a-z]*)(\\d*)'\n",
    "    parts = re.findall(pattern, formula)\n",
    "    element_counts = Counter()\n",
    "    for element, count in parts:\n",
    "        if count == '':\n",
    "            count = 1\n",
    "        else:\n",
    "            count = int(count)\n",
    "        element_counts[element] += count\n",
    "    return element_counts\n",
    "\n",
    "# Function to calculate the average redox potential based on the constituent elements\n",
    "def calculate_average_redox_potential(elements, redox_data):\n",
    "    \"\"\"\n",
    "    Calculate the average redox potential of a material based on its constituent elements.\n",
    "    \"\"\"\n",
    "    total_potential = 0\n",
    "    total_elements = 0\n",
    "    for element, count in elements.items():\n",
    "        element_potential = redox_data[redox_data['from'].str.contains(element)]['potential (V)']\n",
    "        if not element_potential.empty:\n",
    "            total_potential += element_potential.mean() * count\n",
    "            total_elements += count\n",
    "    if total_elements > 0:\n",
    "        return total_potential / total_elements\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Parse the material formulas in `merged_tox_data`\n",
    "merged_tox_data['parsed_formula'] = merged_tox_data['material'].apply(parse_formula)\n",
    "\n",
    "# Calculate the average redox potential for each material\n",
    "merged_tox_data['average_redox_potential (V)'] = merged_tox_data['parsed_formula'].apply(calculate_average_redox_potential, redox_data=redox_redox)\n",
    "\n",
    "# Identify rows with missing 'pot' values\n",
    "missing_pot_indices = merged_tox_data['pot'].isna()\n",
    "\n",
    "# Fill missing 'pot' values with the calculated average redox potentials\n",
    "merged_tox_data.loc[missing_pot_indices, 'pot'] = merged_tox_data.loc[missing_pot_indices, 'average_redox_potential (V)']\n",
    "\n",
    "# Drop the helper columns used for calculation\n",
    "merged_tox_data.drop(columns=['parsed_formula', 'average_redox_potential (V)'], inplace=True)\n",
    "\n",
    "# Save the updated dataset\n",
    "updated_merged_tox_data_path = f\"{directory_path}\\\\Updated_Merged_Tox_Data.csv\"\n",
    "merged_tox_data.to_csv(updated_merged_tox_data_path, index=False)\n",
    "\n",
    "print(f\"Updated dataset saved to {updated_merged_tox_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Getting additional data from Pymatgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.ext.matproj import MPRester\n",
    "from pymatgen.core import Composition\n",
    "\n",
    "# Define your API key for the Materials Project\n",
    "API_KEY = \"eVquqWiqZA7oOoFXmQi\"\n",
    "\n",
    "# Load the updated dataset\n",
    "file_path = \"C:\\\\Users\\\\tikli\\\\Desktop\\\\NanoToxML\\\\Updated_Merged_Tox_Data.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Initialize MPRester with your API key\n",
    "mpr = MPRester(API_KEY)\n",
    "\n",
    "# Function to get properties from Materials Project\n",
    "def get_material_properties(formula):\n",
    "    try:\n",
    "        # Search for materials with the given formula\n",
    "        results = mpr.query({\"pretty_formula\": formula}, \n",
    "                            [\"material_id\", \"band_gap\", \"density\", \"formation_energy_per_atom\"])\n",
    "        if results:\n",
    "            # Get the first result\n",
    "            result = results[0]\n",
    "            return result[\"material_id\"], result[\"band_gap\"], result[\"density\"], result[\"formation_energy_per_atom\"]\n",
    "        else:\n",
    "            return None, None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {formula}: {e}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "# Add new columns to the DataFrame\n",
    "data[\"material_id\"] = None\n",
    "data[\"band_gap\"] = None\n",
    "data[\"density\"] = None\n",
    "data[\"formation_energy_per_atom\"] = None\n",
    "\n",
    "# Loop through the dataset and fetch properties\n",
    "for index, row in data.iterrows():\n",
    "    formula = row[\"material\"]\n",
    "    material_id, band_gap, density, formation_energy = get_material_properties(formula)\n",
    "    data.at[index, \"material_id\"] = material_id\n",
    "    data.at[index, \"band_gap\"] = band_gap\n",
    "    data.at[index, \"density\"] = density\n",
    "    data.at[index, \"formation_energy_per_atom\"] = formation_energy\n",
    "\n",
    "# Save the enhanced dataset\n",
    "enhanced_file_path = \"C:\\\\Users\\\\tikli\\\\Desktop\\\\NanoToxML\\\\After_Pymatgen_Tox_Data.csv\"\n",
    "data.to_csv(enhanced_file_path, index=False)\n",
    "\n",
    "print(f\"Enhanced dataset saved to {enhanced_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Encoding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def encode_column(dataframe, column_name):\n",
    "    \"\"\"Encodes the specified column of the dataframe using unique integer labels.\"\"\"\n",
    "    unique_values = sorted(dataframe[column_name].dropna().unique())\n",
    "    mapping_dict = {value: idx for idx, value in enumerate(unique_values)}\n",
    "    return dataframe[column_name].map(mapping_dict), mapping_dict\n",
    "\n",
    "def main():\n",
    "    # Load the dataset\n",
    "    file_path = 'C:\\\\Users\\\\tikli\\\\Desktop\\\\NanoToxML\\\\Merged_Tox_Data.csv'\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Encoding categorical columns\n",
    "    data['material'], material_map = encode_column(data, 'material')\n",
    "    data['Cell type'], cell_type_map = encode_column(data, 'Cell type')\n",
    "    data['cell source'], cell_source_map = encode_column(data, 'cell source')\n",
    "    data['cell tissue'], cell_tissue_map = encode_column(data, 'cell tissue')\n",
    "    data['test'], test_map = encode_column(data, 'test')\n",
    "    data['test indicator'], test_indicator_map = encode_column(data, 'test indicator')\n",
    "\n",
    "    # Save the encoded dataset\n",
    "    output_path = 'C:\\\\Users\\\\tikli\\\\Desktop\\\\NanoToxML\\\\Tox_DB_Encoded.csv'\n",
    "    data.to_csv(output_path, index=False)\n",
    "    \n",
    "    # Print the mappings for reference\n",
    "    print(\"Material Mapping:\", material_map)\n",
    "    print(\"Cell Type Mapping:\", cell_type_map)\n",
    "    print(\"Cell Source Mapping:\", cell_source_map)\n",
    "    print(\"Cell Tissue Mapping:\", cell_tissue_map)\n",
    "    print(\"Test Mapping:\", test_map)\n",
    "    print(\"Test Indicator Mapping:\", test_indicator_map)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
